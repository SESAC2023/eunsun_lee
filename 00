from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def crawl_articles_with_more_button(url):
    # 웹 드라이버를 초기화하고 페이지 로드
    driver = webdriver.Chrome()  # Chrome 드라이버를 사용하며, 다른 브라우저도 사용 가능합니다.
    driver.get(url)

    # "더보기" 버튼이 나타날 때까지 기다림 (이 부분은 실제 웹 페이지의 동작에 따라 변경되어야 합니다.)
    try:
        more_button = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, "//button[contains(@class, 'more-button')]"))
        )
        while more_button:
            more_button.click()
            more_button = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.XPATH, "//button[contains(@class, 'more-button')]"))
            )
    except:
        print("더보기 버튼을 더 이상 찾을 수 없거나, 클릭할 수 없습니다.")

    # BeautifulSoup를 사용하여 HTML 파싱
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # 기사 제목 추출
    titles = soup.find_all('h2', class_='article-title')
    article_titles = [title.text.strip() for title in titles]

    # 기사 내용 추출
    contents = soup.find_all('div', class_='article-body')
    article_contents = [content.text.strip() for content in contents]

    # 날짜 추출
    dates = soup.find_all('time', class_='date')
    article_dates = [date.text.strip() for date in dates]

    # 드라이버 종료
    driver.quit()

    return article_titles, article_contents, article_dates

if __name__ == "__main__":
    # 크롤링할 URL 설정
    url = "https://www.chosun.com/politics/"

    # 크롤링 시작
    article_titles, article_contents, article_dates = crawl_articles_with_more_button(url)

    # 결과 출력
    for i in range(len(article_titles)):
        print(f"기사 제목: {article_titles[i]}")
        print(f"기사 내용: {article_contents[i]}")
        print(f"날짜: {article_dates[i]}")
        print("=" * 50)
